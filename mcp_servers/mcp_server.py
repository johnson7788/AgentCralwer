#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Date  : 2025/10/13 10:42
# @File  : mcp_href_pdf.py
# @Author: johnson
# @Contact: github: johnson7788
# @Desc  : ä¸‰ç§ä¸åŒç­–ç•¥çš„ PDF ä¸‹è½½å·¥å…· (åŸºäº FastMCP)

import datetime
import os
import asyncio
from fastmcp import FastMCP, Context
from mcp.types import CallToolResult
from common.pdf_utils import get_run_configs, download_with_crawler, fetch_pdfs_from_page
from common.markdown_utils import save_markdown

mcp = FastMCP("PDFDownloader")


# ======================================================
# 1ï¸âƒ£ HREF é“¾æ¥æŠ“å–ä¸‹è½½ï¼šæŸ¥æ‰¾é¡µé¢ä¸­æ‰€æœ‰ä»¥ .pdf ç»“å°¾çš„ href å¹¶ä¸‹è½½
# ======================================================
@mcp.tool()
async def download_pdf_via_href_links(url: str, project_name: str) -> CallToolResult:
    """
    ä»ç½‘é¡µä¸­æå–æ‰€æœ‰ç›´æ¥ä»¥ `.pdf` ç»“å°¾çš„è¶…é“¾æ¥ (href)ï¼Œå¹¶é€šè¿‡æµè§ˆå™¨è‡ªåŠ¨è§¦å‘ä¸‹è½½ã€‚
    é»˜è®¤ä½¿ç”¨è¿™ä¸ªå³å¯ä¸‹åšæ‰€æœ‰pdfæ–‡ä»¶äº†ï¼Œä¼˜å…ˆä½¿ç”¨ã€‚
    ğŸ“˜ ç‰¹ç‚¹:
    - ä½¿ç”¨ crawl4ai çš„å¼‚æ­¥æµè§ˆå™¨ï¼›
    - æ‰«æé¡µé¢ä¸­ `a[href$='.pdf']` ç­‰é“¾æ¥ï¼›
    - é€‚ç”¨äºç›´æ¥å¯è®¿é—®çš„ PDF æ–‡ä»¶é“¾æ¥ï¼›
    - ä¸è§£æ <a type="application/pdf"> ç±»å‹ã€‚

    :param url: ç›®æ ‡ç½‘é¡µ URL
    :param project_name: ä¸‹è½½é¡¹ç›®åç§° (ç”¨äºä¿å­˜ç›®å½•)
    :return: ä¸‹è½½ç»“æœ
    """
    save_dir = os.path.join("./downloaded_pdfs", project_name)
    # meta_in = ctx.request_meta or {}
    run_config = get_run_configs("href_pdf")
    status = await download_with_crawler(url, save_dir, run_config)
    result = f"âœ… [HREFä¸‹è½½æˆåŠŸ]: {url}" if status else f"âŒ [HREFä¸‹è½½å¤±è´¥]: {url}"

    return CallToolResult(
        content=[{"type": "text", "text": result}],
        meta={
            # "user_id": meta_in.get("user_id", "unknown"),
            "server_timestamp": datetime.datetime.utcnow().isoformat() + "Z",
        },
    )


# ======================================================
# 2ï¸âƒ£ MIMEç±»å‹è¯†åˆ«ä¸‹è½½ï¼šæ£€æµ‹ <a type="application/pdf"> æ ‡ç­¾
# ======================================================
@mcp.tool()
async def download_pdf_via_mime_type(url: str, project_name: str) -> CallToolResult:
    """
    é€šè¿‡è¯†åˆ«é¡µé¢ä¸­å£°æ˜ MIME ç±»å‹ä¸º `application/pdf` çš„é“¾æ¥ä¸‹è½½ PDFã€‚

    ğŸ“˜ ç‰¹ç‚¹:
    - åŒæ ·åŸºäº crawl4aiï¼›
    - åŒ¹é… <a type="application/pdf"> æ ‡ç­¾ï¼›
    - é€‚ç”¨äºç½‘ç«™ä½¿ç”¨ MIME ç±»å‹è€Œéåç¼€æ ‡è¯† PDF çš„æƒ…å†µï¼›
    - å…¼å®¹ href å« .pdf çš„å¸¸è§„é“¾æ¥ã€‚

    :param url: ç›®æ ‡ç½‘é¡µ URL
    :param project_name: ä¸‹è½½é¡¹ç›®åç§°
    :return: ä¸‹è½½ç»“æœ
    """
    save_dir = os.path.join("./downloaded_pdfs", project_name)
    # meta_in = ctx.request_meta or {}
    run_config = get_run_configs("application_pdf")
    status = await download_with_crawler(url, save_dir, run_config)
    result = f"âœ… [MIMEä¸‹è½½æˆåŠŸ]: {url}" if status else f"âŒ [MIMEä¸‹è½½å¤±è´¥]: {url}"

    return CallToolResult(
        content=[{"type": "text", "text": result}],
        meta={
            # "user_id": meta_in.get("user_id", "unknown"),
            "server_timestamp": datetime.datetime.utcnow().isoformat() + "Z",
        },
    )


# ======================================================
# 3ï¸âƒ£ é¡µé¢æ­£åˆ™æå–ä¸‹è½½ï¼šè§£æ HTML å¹¶ç”¨ aiohttp ä¸‹è½½ PDF
# ======================================================
@mcp.tool()
async def download_pdf_via_html_parse(url: str, project_name: str) -> CallToolResult:
    """
    ç›´æ¥æŠ“å–ç½‘é¡µ HTML å†…å®¹ï¼Œé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰ PDF é“¾æ¥å¹¶ä¸‹è½½ã€‚

    ğŸ“˜ ç‰¹ç‚¹:
    - ä¸ä¾èµ– JS æ‰§è¡Œï¼›
    - ä½¿ç”¨ aiohttp é€ä¸ªè¯·æ±‚ PDFï¼›
    - é€‚åˆé™æ€é¡µé¢ï¼›
    - æ— æ³•å¤„ç†å¼‚æ­¥åŠ è½½çš„ PDF é“¾æ¥ã€‚

    :param url: ç›®æ ‡ç½‘é¡µ URL
    :param project_name: ä¸‹è½½é¡¹ç›®åç§°
    :return: ä¸‹è½½ç»“æœ
    """
    save_dir = os.path.join("./downloaded_pdfs", project_name)
    # meta_in = ctx.request_meta or {}
    status = await fetch_pdfs_from_page(url, save_dir)
    result = f"âœ… [HTMLè§£æä¸‹è½½æˆåŠŸ]: {url}" if status else f"âŒ [HTMLè§£æä¸‹è½½å¤±è´¥]: {url}"

    return CallToolResult(
        content=[{"type": "text", "text": result}],
        meta={
            # "user_id": meta_in.get("user_id", "unknown"),
            "server_timestamp": datetime.datetime.utcnow().isoformat() + "Z",
        },
    )


# ======================================================
# 4ï¸âƒ£ ç½‘é¡µå†…å®¹ä¿å­˜ä¸º Markdown
# ======================================================
@mcp.tool()
async def save_webpage_as_markdown(url: str, project_name: str) -> CallToolResult:
    """
    æŠ“å–æŒ‡å®š URL çš„ç½‘é¡µå†…å®¹ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸º Markdown æ ¼å¼çš„æ–‡ä»¶ã€‚

    ğŸ“˜ ç‰¹ç‚¹:
    - ä½¿ç”¨ crawl4ai æå–ç½‘é¡µä¸»è¦å†…å®¹å¹¶è½¬æ¢ä¸º Markdownï¼›
    - ä¿å­˜åˆ° `downloaded_markdowns/{project_name}` ç›®å½•ä¸‹ï¼›
    - æ–‡ä»¶ååŸºäºå½“å‰æ—¶é—´æˆ³ç”Ÿæˆã€‚

    :param url: ç›®æ ‡ç½‘é¡µ URL
    :param project_name: é¡¹ç›®åç§° (ç”¨äºä¿å­˜ç›®å½•)
    :return: ä¿å­˜ç»“æœ
    """
    save_dir = os.path.join("./downloaded_markdowns", project_name)
    os.makedirs(save_dir, exist_ok=True)

    # Generate a unique filename using a timestamp
    filename = f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    save_path = os.path.join(save_dir, filename)

    status = await save_markdown(url, save_path)
    result = f"âœ… [Markdown ä¿å­˜æˆåŠŸ]: {save_path}" if status else f"âŒ [Markdown ä¿å­˜å¤±è´¥]: {url}"

    return CallToolResult(
        content=[{"type": "text", "text": result}],
        meta={
            "server_timestamp": datetime.datetime.utcnow().isoformat() + "Z",
        },
    )


if __name__ == "__main__":
    mcp.run(transport="sse")
